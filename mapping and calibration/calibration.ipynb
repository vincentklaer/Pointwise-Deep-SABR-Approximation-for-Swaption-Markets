{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functions import calibration as cal\n",
    "from functions.estimators import Hagan\n",
    "from functions.estimators import NeuralNetwork\n",
    "from functions.estimators import Antonov\n",
    "from functions.estimators import NeuralNetwork\n",
    "import pickle\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import cleaned test dataset\n",
    "with open(\"data generation/test pickles/cleaned_test_chunks.pkl\", \"rb\") as f:\n",
    "    cleaned_chunks = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calibration procedure for all implied volatility curves\n",
    "model = NeuralNetwork() \n",
    "results = Parallel(n_jobs=1)(\n",
    "    delayed(cal.process_chunk)(i, chunk, model, \"nn\") \n",
    "    for i, chunk in enumerate(cleaned_chunks)\n",
    ")\n",
    "\n",
    "with open(\"calibrated_chunks_nn.pkl\", \"wb\") as f:\n",
    "    pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Antonov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calibration procedure for all implied volatility curves\n",
    "model = Antonov() \n",
    "results = Parallel(n_jobs=1)(\n",
    "    delayed(cal.process_chunk)(i, chunk, model, \"antonov\") \n",
    "    for i, chunk in enumerate(cleaned_chunks)\n",
    ")\n",
    "\n",
    "with open(\"calibrated_chunks_antonov.pkl\", \"wb\") as f:\n",
    "    pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hagan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calibration procedure for all implied volatility curves\n",
    "model = Hagan() \n",
    "results = Parallel(n_jobs=1)(\n",
    "    delayed(cal.process_chunk)(i, chunk, model, \"hagan\") \n",
    "    for i, chunk in enumerate(cleaned_chunks)\n",
    ")\n",
    "\n",
    "with open(\"calibrated_chunks_hagan.pkl\", \"wb\") as f:\n",
    "    pickle.dump(results, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
